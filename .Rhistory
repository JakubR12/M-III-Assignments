setwd("~/M-III-Assignments")
library(pacman)
pacman::p_load(dplyr,tidyverse,janitor,reshape,stringr)
#loading data
demo_train<-read.csv(file='demo_train.csv',header=TRUE,sep=",")
token_train<-read.csv(file='token_train.csv',header=TRUE,sep=",")
LU_train<-read.csv(file='LU_train.csv',header=TRUE,sep=",")
#explore data
head(demo_train)
#changing column names, be careful about reshape dplyr package, both contains the same function!  to resolve link below
demo_train <- demo_train %>%
rename (c(
"Child.ID" = "SUBJ"
))
demo_train <- demo_train %>%
rename (c(
"Visit" = "VISIT"
))
demo_train
LU_train
token_train
#unifying rows in VISIT columns across dataframes
LU_train$VISIT<-str_extract(LU_train$VISIT, "\\d")
token_train$VISIT<-str_extract(token_train$VISIT, "\\d")
#deleting dots after full name in LU_train and token_train
#deleting all dots from all 3 databases
demo_train$SUBJ<-str_replace_all(demo_train$SUBJ,"[.]", "")
LU_train$SUBJ<-str_replace_all(LU_train$SUBJ,"[.]", "")
token_train$SUBJ<-str_replace_all(token_train$SUBJ,"[.]", "")
head(demo_train)
LU_train
token_train
###selecting only desired columns
#demo_train
dm_fil<- select(demo_train, SUBJ, VISIT, Diagnosis,Ethnicity,Gender,Age, ADOS,MullenRaw,ExpressiveLangRaw,Socialization)
#LU_train
lut_fil<- select(LU_train,1:3, 8)
#token_train
tt_fil<- select(token_train,1:4, 6:7)
#dm_fil$SUBJ<- as.character(dm_fil$SUBJ)
#lut_fil$SUBJ<- as.character(lut_fil$SUBJ)
#tt_fil$SUBJ<- as.character(tt_fil$SUBJ)
combined_easy<- merge(tt_fil, lut_fil, all = TRUE)
final_df<- merge (combined_easy, dm_fil, all = FALSE)
visit1<- filter(final_df, VISIT == 1)
#anonymizeing
p_load(digest)
#thank some geek to
anonymise <- function(data, cols_to_anon, algo = "sha256")
{
if(!require(digest)) stop("digest package is required")
to_anon <- subset(data, select = cols_to_anon)
unname(apply(to_anon, 1, digest, algo = algo))
}
pacman$method3_id <- anonymise(pacman, cols_to_anon)
#anonymizeing
p_load(digest)
#thank some geek to
anonymise <- function(data, cols_to_anon, algo = "sha256")
{
if(!require(digest)) stop("digest package is required")
to_anon <- subset(data, select = cols_to_anon)
unname(apply(to_anon, 1, digest, algo = algo))
}
#re-naming levels of gender,
visit1$Gender<- ifelse(visit1$Gender == 1, "M", "F" )
#making csv file
write.csv(final_df, file = "prepared_data.csv")
View(visit1)
#anonymizeing
p_load(digest)
#thank some geek to
anonymise <- function(data, cols_to_anon, algo = "sha256")
{
if(!require(digest)) stop("digest package is required")
to_anon <- subset(data, select = cols_to_anon)
unname(apply(to_anon, 1, digest, algo = algo))
}
#re-naming levels of gender,
visit1$Gender<- ifelse(visit1$Gender == 1, "M", "F" )
#making csv file
write.csv(final_df, file = "prepared_data.csv")
View(visit1)
anonymise <- function(data, cols_to_anon, algo = "sha256")
{
if(!require(digest)) stop("digest package is required")
to_anon <- subset(data, select = cols_to_anon)
unname(apply(to_anon, 1, digest, algo = algo))
}
View(visit1)
View(visit1)
filter(visit1, CHI_MLU >> 2.7)
filter(visit1, CHI_MLU > 2.7)
#1CHI_MLU all visit
filter(final_df, CHI_MLU > 2.7)
#2
filter(visit1, CHI_MLU > 2.7)
#1CHI_MLU all visit
filter(final_df, CHI_MLU > 2.7)
complete.cases(df_final)
complete.cases(final_df)
#3
filter(final_df,CHI_MLU == "NA" )
#3
filter(final_df,CHI_MLU == "NA" )
#3
filter(final_df,[1:16] == "NA" )
#3
filter(final_df, [1:16] == "NA" )
#3
filter(final_df, final_df[1:16] == "NA" )
is.na(final_df)
#3
filter(final_df) %>% is.na(final_df)
#3
filter(final_df) %>%
is.na(final_df)
expr[final_df == "NA", ]
expr[final_df == "NA"]
filter(!complete.cases(final_df[1:15]))
final_df%>% filter(!complete.cases(final_df[1:15]))
final_df %>% filter(final_df, VISIT == 6) %>%
arrange(final_df, tokens_CHI)VISIT ==6
final_df %>% filter(VISIT == 6) %>%
arrange(final_df, tokens_CHI)VISIT ==6
final_df %>% filter(VISIT == 6) %>%
arrange(tokens_CHI)VISIT ==6
final_df %>% filter(VISIT == 6) %>%
arrange(tokens_CHI)
#2
final_df %>% filter(VISIT == 1) %>%
arrange(desc(tokens_CHI))
#2
final_df %>% filter(VISIT == 1) %>%
arrange(desc(tokens_CHI))
#1
final_df %>% filter(VISIT == 6) %>%
arrange(tokens_CHI)
#2
final_df %>% filter(VISIT == 1) %>%
arrange(desc(tokens_CHI))
#2
final_df %>% filter(VISIT == 1) %>%
arrange(desc(tokens_CHI))
#2
final_df %>% filter(VISIT == 1) %>%
arrange(desc(tokens_CHI))
#1
final_df %>% filter(VISIT == 6) %>%
arrange(tokens_CHI)
#1
final_df %>% filter(VISIT == 6) %>%
arrange(desc(tokens_CHI))
#2
final_df %>% filter(VISIT == 1) %>%
arrange(tokens_CHI)
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI)
#2
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI, tokens_CHI)
#1
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI)
#2
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI, tokens_CHI)
#1
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI)
#2
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI, tokens_CHI)
#1
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI)
#2
final_df %>% filter(Diagnosis == "A") %>% select(CHI_MLU,tokens_CHI, tokens_CHI)
cbind(final_df, meanNW)
colnames(final_df)<- C([1:15], "newcolumn")
mean(df_final$tokens_CHI[1:6])
mean(final_df$tokens_CHI[1:6])
mutate(final_df, mean(final_df$tokens_CHI[1:6])
mutate(final_df, mean(final_df$tokens_CHI[1:6])
mutate(final_df, newco=mean(final_df$tokens_CHI[1:6])
mutate(final_df, newco=mean(final_df$tokens_CHI[1:6])
mutate(final_df, newco=mean(final_df$tokens_CHI[1:6])
mutate(final_df, newco=mean(final_df$tokens_CHI[1:6])
group_by(final_df, SUBJ, VISIT) %>%
summarise_each(funs(mean(., na.rm = TRUE)), tokens_CHI)
final_df
group_by(final_df, SUBJ, VISIT) %>%
summarise_each(funs(mean(., na.rm = TRUE)), tokens_CHI)
group_by(final_df, SUBJ, VISIT) %>%
summarise_each(funs(mean(tokens_CHI, na.rm = TRUE)), tokens_CHI)
group_by(final_df, SUBJ, VISIT) %>%
summarise_each(funs(mean(tokens_CHI)), tokens_CHI)
group_by(final_df, SUBJ) %>%
summarise_each(funs(mean(tokens_CHI)), tokens_CHI)
group_by(final_df, SUBJ) %>%
summarise_each(funs(mean(tokens_CHI)))
group_by(final_df, SUBJ) %>%
summarise_each(funs(mean(tokens_CHI) tokens_CHI))
tokens_CHI
group_by(final_df, SUBJ) %>%
summarise_each(funs(mean(tokens_CHI)), tokens_CHI)
#2
group_by(final_df, SUBJ, VISIT) %>%
summarise(funs(mean(tokens_CHI)), tokens_CHI)
#2
group_by(final_df, SUBJ, VISIT) %>%
summarise_each(funs(mean(tokens_CHI)), tokens_CHI)
group_by(final_df, SUBJ) %>%
summarise_each(funs(mean(tokens_CHI)), tokens_CHI)
group_by(final_df, SUBJ) %>%
mutate(summarise_each(funs(mean(tokens_CHI)), tokens_CHI))
group_by(final_df, SUBJ) %>%
summarise_each(funs(mean(tokens_CHI)), tokens_CHI)
#2
group_by(final_df, SUBJ) %>%
summarise(meanword=mean(tokens_CHI))
cbind(final_df, meanworld)
#2
group_by(final_df, SUBJ) %>%
summarise(meanword=mean(tokens_CHI))
cbind(final_df, meanworld)
#2
group_by(final_df, SUBJ) %>%
summarise(meanword=mean(tokens_CHI))
#2
group_by(final_df, SUBJ) %>%
summarise(meanword=mean(tokens_CHI)) %>%
cbind(meanworld)
#2
group_by(final_df, SUBJ) %>%
tokensmean<-summarise(meanword=mean(tokens_CHI)) %>%
cbind(tokensmean)
#2
group_by(final_df, SUBJ) %>%
tokensmean<-summarise(meanword=mean(tokens_CHI)) %>%
cbind(tokensmean)
#2
group_by(final_df, SUBJ) %>%
summarise(meanword=mean(tokens_CHI)) %>%
assign(x="a", value =".")
#2
group_by(final_df, SUBJ) %>%
summarise(meanword=mean(tokens_CHI)) %>%
assign(x="a", value =".")
meantoken<- c()
group_by(final_df, SUBJ) %>%
summarise(meantoken=mean(tokens_CHI))
group_by(final_df, SUBJ) %>%
summarise(meantoken=mean(tokens_CHI)) %>%
cbind(final_df, meantoken)
#2
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI))
meantoken<-final_df %>%
group_by(final_df, SUBJ) %>%
summarise(meantoken=mean(tokens_CHI)) %>%
cbind(final_df, meantoken)
meantoken<-final_df %>%
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI)) %>%
#2
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI))
meantoken<- final_df %>%
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI)) %>%
#2
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI))
meantoken <- final_df %>%
group_by(SUBJ) %>%
summarise(mean(tokens_CHI)) %>%
#2
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI))
meantoken <- final_df %>%
group_by(SUBJ) %>%
summarise(mean(tokens_CHI))
View(meantoken)
mutate(final_df, meantoken$`mean(tokens_CHI)`)
mutate(final_df, mean(final_df$tokens_CHI))
visit_tokens <- vector("numeric") #creating and empty vector
for (i in final_df$VISIT){
sub=filter(final_df, VISIT==i)
mean=mean(sub$tokens_CHI)
print(mean)
visit_tokens <- rbind(visit_tokens, mean)
}#Looping through each visit and adding the mean value to each visit for each row.
asd_full_df <- mutate(asd_full_df, visit_tokens) #Appending it to the master data frame
final_df <- mutate(final_df, visit_tokens) #Appending it to the master data frame
#2
group_by(final_df, SUBJ) %>%
summarise(mean(tokens_CHI))
setwd("~/M-III-Assignments")
library(pacman)
pacman::p_load(dplyr,tidyverse,janitor,reshape,stringr)
#loading data
demo_train<-read.csv(file='demo_train.csv',header=TRUE,sep=",")
token_train<-read.csv(file='token_train.csv',header=TRUE,sep=",")
LU_train<-read.csv(file='LU_train.csv',header=TRUE,sep=",")
#explore data
head(demo_train)
#changing column names, be careful about reshape dplyr package, both contains the same function!  to resolve link below
demo_train <- demo_train %>%
rename (c(
"Child.ID" = "SUBJ"
))
demo_train <- demo_train %>%
rename (c(
"Visit" = "VISIT"
))
demo_train
LU_train
token_train
#unifying rows in VISIT columns across dataframes
LU_train$VISIT<-str_extract(LU_train$VISIT, "\\d")
token_train$VISIT<-str_extract(token_train$VISIT, "\\d")
#deleting dots after full name in LU_train and token_train
#deleting all dots from all 3 databases
demo_train$SUBJ<-str_replace_all(demo_train$SUBJ,"[.]", "")
LU_train$SUBJ<-str_replace_all(LU_train$SUBJ,"[.]", "")
token_train$SUBJ<-str_replace_all(token_train$SUBJ,"[.]", "")
head(demo_train)
LU_train
token_train
###selecting only desired columns
#demo_train
dm_fil<- select(demo_train, SUBJ, VISIT, Diagnosis,Ethnicity,Gender,Age, ADOS,MullenRaw,ExpressiveLangRaw,Socialization)
#LU_train
lut_fil<- select(LU_train,1:3, 8)
#token_train
tt_fil<- select(token_train,1:4, 6:7)
#dm_fil$SUBJ<- as.character(dm_fil$SUBJ)
#lut_fil$SUBJ<- as.character(lut_fil$SUBJ)
#tt_fil$SUBJ<- as.character(tt_fil$SUBJ)
combined_easy<- merge(tt_fil, lut_fil, all = TRUE)
final_df<- merge (combined_easy, dm_fil, all = FALSE)
visit1<- filter(final_df, VISIT == 1)
#anonymizeing
p_load(digest)
#thank some geek to
anonymise <- function(data, cols_to_anon, algo = "sha256")
{
if(!require(digest)) stop("digest package is required")
to_anon <- subset(data, select = cols_to_anon)
unname(apply(to_anon, 1, digest, algo = algo))
}
pacman$method3_id <- anonymise(pacman, cols_to_anon)
visit1_$SUBJ <- anonymise(visit1, cols_to_anon)
visit1_$SUBJ <- anonymise(visit1, cols_to_anon=SUBJ)
visit1_$SUBJ <- anonymise(visit1, cols_to_anon="SUBJ")
visit1$SUBJ <- anonymise(visit1, cols_to_anon="SUBJ")
View(visit1)
#making csv file
write.csv(final_df, file = "prepared_data.csv")
View(visit1)
#re-naming levels of gender,
visit1$Gender<- ifelse(visit1$Gender == 1, "M", "F" )
#making csv file
write.csv(visit1, file = "prepared_data.csv")
View(visit1)
